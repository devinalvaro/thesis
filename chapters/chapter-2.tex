\chapter{Studi Literatur}

\section{\en{Deep Learning}}

\en{Deep learning} adalah suatu bagian dari bidang \en{machine learning}, di mana pembelajaran dilakukan pada \en{neural network} dengan \en{layer} berjumlah banyak \citep{deng2014deep}. Berbagai arsitektur \en{deep learning} seperti \en{convolutional neural network} (CNN) dan \en{recurrent neural network} (RNN) telah banyak diaplikasikan pada berbagai bidang AI, seperti \en{computer vision} dan \en{speech recognition}.

Berikut akan dijelaskan lebih dalam mengenai \en{deep learning}, termasuk salah satu jenis arsitektur dan metode pelatihannya.

\subsection{\en{Overview}}

TBD.

\subsection{\en{Recurrent Neural Network}}

TBD.

\subsection{Proses Pelatihan}

Terdapat berbagai macam metode pelatihan model \en{deep learning}, salah satunya adalah \en{stochastic gradient descent} (SGD). Pada SGD, keseluruhan \en{dataset} dibagi menjadi beberapa \en{mini-batch} (atau \en{batch}). Pada setiap \en{batch}, gradien dihitung kemudian digunakan untuk meng-\en{update} parameter, agar menurunkan \en{loss} atau \en{error}.

Apabila pelatihan telah selesai memproses seluruh \en{batch}, maka disebut telah menyelesaikan satu \en{epoch}. Biasanya, pelatihan terdiri dari banyak \en{epoch}. Tujuan SGD membagi \en{dataset} ke \en{batch}-\en{batch} adalah mempercepat konvergensi dan menghemat penggunaan memori karena pada satu waktu hanya perlu diproses sebagian \en{training data} saja. Namun, karena gradien yang didapat pada suatu \en{batch} hanya berdasarkan sebagian sampel data saja, maka gradien ini sejatinya adalah estimasi dari gradien yang seharusnya (gradien populasi). Hal ini dapat menyebabkan penurunan kinerja model, meski pada praktiknya penurunan kinerja ini dapat saja diterima demi meningkatkan kecepatan pelatihan dan mengurangi penggunaan memori.

\subsection{Penggunaan Memori}

Berbagai penelitian menunjukkan bahwa pada model \en{deep learning}, menambah jumlah neuron dan \en{hidden layer} dapat meningkatkan kinerja model \citep{dean2012large,nielsen2015neural}. Tetapi, meningkatkan kompleksitas model seperti demikian juga meningkatkan \en{training cost}, seperti waktu pelatihan dan ukuran memori yang dibutuhkan. Gambar ~\ref{fig:MemoryVSBatchSize} menunjukkan utilisasi memori beberapa \en{pre-trained model} terhadap ukuran \en{batch}. Berikutnya, akan dibahas beberapa penyebab meningkatnya kebutuhan memori pada model \en{deep learning} seiring meningkatnya kompleksitas model.

TBD.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/memory-vs-batch-size.png}
    \caption{Utilisasi memori berbagai model \en{deep learning} terhadap ukuran \en{batch} \citep{canziani2016analysis}.}
    \label{fig:MemoryVSBatchSize}
\end{figure}

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/resnet50-memory.png}
    \caption{Penggunaan memori pada model ResNet-50 \citep{meng2017training}.}
    \label{fig:ResNet50Memory}
\end{figure}

\section{Graphics Processing Unit}

Penggunaan GPU pada pelatihan \en{deep learning} merupakan salah satu faktor yang memajukan perkembangan bidang ini secara signifikan \citep{dean2012large}. Hal ini dikarenakan GPU mampu meningkatkan kecepatan dengan menjalankan pelatihan secara paralel. Sayangnya, ukuran memori GPU lebih terbatas, yakni 8-10 kali lebih kecil dari memori CPU. Sebagai gambaran, pada saat penulisan tulisan ini, \en{high-end} GPU rata-rata memiliki 12-16GB memori, sedangkan memori CPU dapat mencapai 128GB \citep{meng2017training}.

Padahal, kekurangan memori dapat menyebabkan kegagalan pelatihan model (\en{out of memory}). Solusi yang biasa diterapkan adalah mengurangi ukuran \en{dataset}, ukuran \en{batch}, atau jumlah parameter model, meskipun hal ini dapat menurunkan kinerja model \citep{meng2017training}.

Selain solusi-solusi tersebut, terdapat juga metode \en{memory swapping}, yaitu memindahkan sebagian data dari memori GPU ke CPU saat pelatihan. Akan tetapi, \en{memory swapping} yang terlalu sering dapat menurunkan kecepatan pelatihan secara signifikan karena adanya \en{data transfer overhead} \citep{dean2012large}.

TBD.

\section{TensorFlow}

TensorFlow adalah sistem pembelajaran mesin yang didesain untuk menangani pelatihan model berskala besar dan secara terdistribusi, baik untuk kebutuhan penelitian maupun industri. Dikembangkan oleh tim Google Brain dan dirilis secara \en{open source}, TensorFlow telah digunakan secara ekstensif pada berbagai proyek pembelajaran mesin, baik di dalam maupun di luar Google.

Pada dasarnya, TensorFlow adalah \en{framework} yang menyediakan operasi-operasi komputasi matematika (seperti aljabar linear dan kalkulus), dengan operasi-operasi tambahan yang memudahkan pendefinisian proses pembelajaran mesin. Dengan TensorFlow, eksekusi operasi-operasi tersebut dapat dilakukan secara terdistribusi menggunakan berbagai \en{device} seperti CPU, GPU, maupun TPU (Tensor Processing Units) yang terdapat pada satu atau lebih \en{machine} yang terletak pada satu atau lebih \en{cluster}. Selain itu, TensorFlow juga berjalan di berbagai macam platform, mulai dari \en{data center} hingga \en{smartphone} \citep{abadi2016tensorflow}.

\subsection{Komputasi}

Seluruh operasi dan data pada program TensorFlow beserta hubungannya membentuk sebuah \en{dataflow graph}. Operasi merupakan \en{vertice} dari graf tersebut. Sedangkan data yang pada TensorFlow direpresentasikan sebagai \en{tensor} (vektor multi-dimensional) mengalir (\en{flowing}) melalui \en{edge}-\en{edge} dari graf.

Salah satu tujuan representasi program dengan \en{dataflow graph} adalah memudahkan komputasi program secara terdistribusi. Seperti diilustrasikan oleh Gambar ~\ref{fig:TensorFlowGraph}, graf dapat dibagi-bagi menjadi beberapa subgraf, di mana setiap subgraf dieksekusi oleh \en{device} yang berbeda-beda. Dengan membagi menjadi beberapa subgraf, sebuah \en{device} baru perlu berkomunikasi dengan \en{device} lainnya apabila masuk \en{vertice} yang memiliki \en{dependency} ke \en{vertice} di \en{device} lain.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/tensorflow-graph.png}
    \caption{\en{Dataflow graph} dari program TensorFlow \citep{geron2017hands}.}
    \label{fig:TensorFlowGraph}
\end{figure}

\subsection{Arsitektur}

Gambar ~\ref{fig:TensorFlowArch} menunjukkan arsitektur umum TensorFlow. Berikut ini akan dijelaskan beberapa bagian dari arsitektur tersebut.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.50\linewidth]{figures/tensorflow-arch.png}
    \caption{Arsitektur umum TensorFlow \citep{tensorflow2018architecture}.}
    \label{fig:TensorFlowArch}
\end{figure}

\textbf{Client}. Menerima pendefinisian program TensorFlow dari \en{user}, seperti \en{tensor}-\en{tensor} yang ada dan operasi-operasi yang dijalankan. Kemudian \en{client} mengkonstruksi \en{dataflow graph} yang sesuai, lalu mengeksekusi graf tersebut menggunakan \en{session}. \en{Client} tersedia dalam beberapa bahasa, seperti Python, Go, dan C++.

\textbf{Distributed Master.} Merupakan koordinator dari keseluruhan program TensorFlow. Setelah menerima \en{dataflow graph} dari \en{client}, \en{distributed master} mempartisi graf menjadi beberapa subgraf, kemudian mendistribusikannya ke \en{worker services}.

\textbf{Worker Services.} Menerima \en{request} dari \en{master}, menjalankannya pada \en{devices} di bawahnya, kemudian mengirim hasilnya kembali ke \en{master}. \en{Worker service} berelasi satu-satu dengan \en{task}. \en{Task} pada TensorFlow merujuk pada suatu proses TensorFlow, di mana suatu \en{machine} dapat memiliki satu atau lebih \en{task}. Bahkan, suatu \en{device} dari suatu \en{machine} dapat dibagi-bagi ke beberapa \en{task}.

\textbf{Kernel Implementations.} Merupakan implementasi operasi-operasi TensorFlow yang \en{device-specific}. Tanpa \en{kernel implementation} yang sesuai, \en{backend} TensorFlow tidak dapat berjalan pada suatu \en{device}.

Gambar ~\ref{fig:TensorFlowDist} mengilustrasikan hubungan antar bagian TensorFlow tersebut dalam pelatihan terdistribusi.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/tensorflow-dist.png}
    \caption{Hubungan bagian-bagian terdistribusi di TensorFlow \citep{tensorflow2018architecture}.}
    \label{fig:TensorFlowDist}
\end{figure}

\subsection{Penambahan Operasi}

TensorFlow mendukung penambahan jenis operasi baru, apabila jenis-jenis operasi yang disediakan belum memenuhi kebutuhan pengguna, atau mengoptimisasi operasi yang ada secara \en{native}. Untuk membuat operasi baru, pengguna perlu menambahkan definisi (seperti \en{input} dan \en{output}, bentuk \en{tensor}) dan implementasi operasi tersebut dalam bahasa C++. Selanjutnya, pengguna dapat menambahkan API ke operasi tersebut pada \en{client}, namun langkah ini bersifat opsional.

\section{Penelitian Terkait}

"Training deeper models by GPU memory optimization on TensorFlow" (Meng, 2017) merupakan penelitian untuk mengoptimisasi penggunaan memori GPU pada pelatihan model \en{deep learning} dengan TensorFlow \citep{meng2017training}. Penelitian tersebut terbatas pada sebuah komputer dengan satu GPU. Ide dari \en{paper} tersebut adalah menyimpan sebagian model dari memori GPU ke memori CPU saat pelatihan untuk mengurangi beban memori GPU.

Optimisasi dilakukan dengan mengimplementasikan operasi baru yang disebut (\textbf{swap out/in}) untuk men-\en{swap} \en{tensor} dari memori GPU ke CPU. Dengan operasi baru ini, graf TensorFlow yang sudah ada dimodifikasi sehingga operasi disisipkan ke hubungan \en{vertice} yang mengalirkan tensor yang di-\en{swap}. Operasi \textbf{swap out/in} ini diilustrasikan oleh Gambar ~\ref{fig:SwapOutIn}.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/swap-out-in.png}
    \caption{Graf yang dimodifikasi dengan menyisipkan operasi \textbf{swap out/in} \citep{meng2017training}.}
    \label{fig:SwapOutIn}
\end{figure}

Agar dapat mengoptimisasi dengan baik, perlu dipertimbangkan \en{tensor} mana yang perlu di-\en{swap}. Apabila semua \en{tensor} di-\en{swap}, akan menyebabkan penurunan kinerja model karena \en{data transfer overhead}. Maka dari itu, \en{tensor} terbaik untuk di-\en{swap} adalah yang interval hingga diperlukannya kembali cukup lama.

Eksperimen pada \en{paper} dilakukan dengan beberapa \en{pre-trained model} seperti ResNet, Inception, dan NMT, pada sebuah komputer dengan satu GPU (Tesla M40) dengan kapasitas memori 12GB. Menurut eksperimen tersebut, didapatkan bahwa pada model-model yang diuji, ukuran \en{batch} dapat ditingkatkan hingga 3 kali, sedangkan penggunaan memori maksimum menurun hingga 2-3 kali lipat. Bahkan, model-model seperti ResNet-1001 dan ResNet-2000 yang sebelumnya tidak dapat dilatih karena \en{out of memory} (OOM), menjadi dapat dilatih. Di sisi lain, \en{training speed} mengalami penurunan kurang dari 10\%, karena adanya \en{data transfer overhead}.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/swap-out-in-result.png}
    \caption{Perbandingan penggunaan memori dengan \textbf{swap out/in} \citep{meng2017training}.}
    \label{fig:SwapOutInResult}
\end{figure}
