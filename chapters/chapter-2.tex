\chapter{Studi Literatur}

\section{Deep Learning}

\en{Deep learning} adalah suatu bagian dari bidang \en{machine learning}, di mana pembelajaran mesin dilakukan dengan unit-unit dalam \en{layer} berjumlah banyak \cite{deng2014deep}. Berbagai arsitektur \en{deep learning} seperti \en{convolutional neural network} (CNN) dan \en{recurrent neural network} (RNN) telah banyak diaplikasikan pada berbagai bidang AI, seperti \en{computer vision} dan \en{speech recognition}.

\subsection{Arsitektur}

Arsitektur \en{deep learning} sangat beragam sehingga tidak semuanya dapat dibahas secara detail, oleh karena itu hanya akan dibahas secara singkat beberapa arsitektur \en{deep learning} yang relevan dengan tulisan ini, yaitu CNN.

Pada CNN, neuron-neuron pada suatu \en{layer} tidak selalu tersusun secara 1 dimensi, namun dapat tersusun secara n-dimensi. Selain itu, suatu neuron tidak memiliki hubungan satu-satu dengan neuron-neuron di \en{layer} selanjutnya. Melainkan, kumpulan \en{weight} dan \en{bias} beberapa neuron sekaligus menjadi input dari fungsi aktivasi ke sebuah neuron di \en{layer} selanjutnya. Hubungan antar \en{layer} pada CNN tersebut diilustrasikan oleh Gambar ~\ref{fig:FeatureMap}. Inilah yang disebut \en{feature map}, yaitu \en{mapping} dari kumpulan neuron di suatu \en{layer} ke suatu neuron di \en{layer} selanjutnya.

Secara intuitif, kegunaan \en{feature map} adalah mengenali fitur pada suatu \en{layer}, untuk kemudian diserahkan ke \en{layer} selanjutnya. Maka dari itu, pada umumnya setiap \en{layer} menggunakan banyak \en{feature map} yang diinisialisasi secara acak, dengan harapan bahwa setelah \en{training}, setiap \en{feature map} mengenali fitur-fitur yang berbeda pada suatu \en{layer}.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/feature-map.png}
    \caption{\en{Feature map} pada CNN \citep{nielsen2015neural}.}
    \label{fig:FeatureMap}
\end{figure}

Sebagai contoh, arsitektur CNN untuk MNIST ditunjukkan oleh Gambar ~\ref{fig:CNN}. Pada \en{input layer}, terdapat 28x28 neuron (1 neuron untuk setiap pixel pada gambar berukuran 28x28 pixel). Pada gambar tersebut, \en{input layer} terhubung ke \en{layer} selanjutnya dengan 3 \en{feature map}, begitu seterusnya hingga \en{output layer}.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/cnn.png}
    \caption{Contoh arsitektur CNN untuk MNIST \citep{nielsen2015neural}.}
    \label{fig:CNN}
\end{figure}

\subsection{Proses Training}

Ada berbagai macam metode pelatihan model \en{deep learning}, tetapi akan dibahas salah satu metode yang paling populer, yaitu \en{stochastic gradient descent} (SGD). Pada SGD, keseluruhan \en{dataset} dibagi menjadi beberapa \en{mini-batch} (atau \en{batch}). Pada setiap \en{batch}, gradien dihitung kemudian digunakan untuk \en{update} parameter, agar menurunkan \en{loss} atau \en{error}.

Apabila \en{training} telah selesai memproses seluruh \en{batch}, maka disebut telah menyelesaikan satu \en{epoch}. Biasanya, \en{training} terdiri dari banyak \en{epoch}. Tujuan SGD membagi \en{dataset} ke \en{batch}-\en{batch} adalah mempercepat konvergen dan menghemat memori karena pada satu waktu hanya perlu diproses sebagian \en{training sample} saja. Sayangnya, karena gradien yang didapat pada suatu \en{batch} hanya berdasarkan beberapa \en{training sample} saja, maka gradien ini sejatinya adalah estimasi dari gradien sebenarnya. Hal ini dapat menyebabkan penurunan kinerja model, namun pada praktiknya penurunan ini dapat diterima,

\subsection{Penggunaan Memori}

Berbagai penelitian menunjukkan bahwa pada model \en{deep learning}, menambah jumlah neuron dan \en{hidden layer} dapat meningkatkan kinerja model \citep{dean2012large,nielsen2015neural}. Tetapi, meningkatkan kompleksitas model seperti demikian juga meningkatkan \en{training cost}, seperti waktu \en{training} dan memori yang dibutuhkan. Gambar ~\ref{fig:MemoryVSBatchSize} menunjukkan utilisasi memori beberapa \en{pre-trained model} terhadap ukuran \en{batch}. Berikutnya, akan dibahas beberapa penyebab meningkatnya kebutuhan memori pada model \en{deep learning} seiring meningkatnya kompleksitas model.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/memory-vs-batch-size.png}
    \caption{Utilisasi memori berbagai model \en{deep learning} terhadap ukuran \en{batch} \citep{canziani2016analysis}.}
    \label{fig:MemoryVSBatchSize}
\end{figure}

\textbf{Feature Map.} Jumlah feature map meningkat seiring bertambahnya \en{hidden layer}, karena setiap \en{layer} membutuhkan \en{mapping} ke \en{layer} selanjutnya. Sedangkan ukuran \en{feature map} ditentukan oleh berbagai faktor, seperti ukuran \en{batch} dan \en{stride}. Gambar ~\ref{fig:ResNet50Memory} menunjukkan penggunaan memori model ResNet-50 pada satu iterasi \en{mini-batch training} pada \en{dataset} ImageNet. Penggunaan memory ResNet-50 mengalami \en{peak} pada sekitar 5GB, kemudian mengalami penurunan karena \en{feature map} yang sudah tidak dibutuhkan akan didealokasi.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/ResNet50-memory.png}
    \caption{Penggunaan memori pada model ResNet-50 \citep{meng2017training}.}
    \label{fig:ResNet50Memory}
\end{figure}

\textbf{Bias.} Jumlah \en{bias} meningkat dengan bertambahnya \en{hidden layer}, karena setiap neuron pada setiap \en{hidden layer} memiliki \en{bias} sendiri. Akan tetapi, bila dibandingkan dengan \en{feature map}, penggunaan memori dari \en{bias} relatif sedikit. Hanya saja, tidak seperti \en{feature map}, bias tidak pernah dialokasi di sepanjang proses \en{training}.

\textbf{Temporary memory.} Beberapa algoritma komputasi pada training \en{deep learning} membutuhkan memori, seperti FFT (fast Fourier transform). Tetapi, penggunaan memori seperti ini relatif kecil dan cepat didealokasi, tepatnya setelah algoritma selesai dieksekusi.

Dari beberapa penyebab penggunaan memori pada \en{deep learning} tersebut, \en{feature map} merupakan pengguna memori tertinggi. Selain itu, \en{feature map} memiliki beberapa properti khusus yang dapat dimanfaatkan untuk optimisasi. Salah satu properti tersebut adalah sifatnya yang berbasis \en{layer}, sehingga bila pada \en{feed-forward} proses \en{training} telah maju ke \en{layer} selanjutnya, \en{feature map} dari \en{layer-layer} sebelumnya tidak digunakan hingga \en{backpropagation}.

\section{Graphics Processing Unit}

Penggunaan GPU pada proses \en{machine learning}/\en{deep learning} meningkatkan kecepatan \en{training} secara signifikan. Sayangnya, memori GPU lebih terbatas dibanding memori CPU. Sebagai gambaran, \en{high-end} GPU dilengkapi 12-16GB memori, sedangkan memori dari CPU server dapat mencapai 128GB.

Padahal, peningkatan kecepatan \en{training} dengan GPU menjadi kecil apabila memori GPU tidak cukup, karena terjadinya \en{memory bottleneck} \citep{dean2012large}. Solusi yang biasa digunakan adalah mengurangi ukuran \en{dataset} atau parameter model, meskipun hal ini dapat menurunkan kinerja model.

\subsection{Memori}

TBD.

\section{TensorFlow}

TensorFlow adalah sistem pembelajaran mesin yang didesain untuk menangani training model berskala besar dan secara terdistribusi, baik untuk kebutuhan \en{research} maupun \en{production}. Dikembangkan oleh tim Google Brain dan dirilis secara \en{open source}, TensorFlow telah digunakan secara ekstensif pada berbagai proyek \en{machine learning}, baik di dalam maupun di luar Google.

Pada dasarnya, TensorFlow adalah \en{framework} yang menyediakan operasi-operasi komputasi matematika (terutama aljabar linear dan kalkulus), dengan operasi-operasi tambahan yang memudahkan pendefinisian proses \en{machine learning}. Dengan TensorFlow, eksekusi operasi-operasi tersebut dapat dilakukan secara terdistribusi menggunakan berbagai \en{device} seperti CPU, GPU, maupun TPU (Tensor Processing Units) yang terdapat pada satu atau lebih \en{machine} yang terletak pada satu atau lebih \en{cluster}. Selain itu, TensorFlow juga berjalan di berbagai macam \en{platform}, dari \en{data center} hingga \en{mobile}.

\subsection{Komputasi}

Seluruh operasi dan data pada program TensorFlow beserta hubungannya membentuk sebuah \en{dataflow graph}. Operasi merupakan \en{vertice} dari graf tersebut. Sedangkan data, yang pada TensorFlow direpresentasikan sebagai \en{tensor} (vektor multi-dimensional) mengalir (\en{flowing}) melalui \en{edge}-\en{edge} dari graf.

Salah satu tujuan representasi program dengan \en{dataflow graph} adalah memudahkan komputasi program secara terdistribusi. Seperti diilustrasikan oleh Gambar ~\ref{fig:TensorFlowGraph}, graf dapat dibagi-bagi menjadi beberapa subgraf, di mana setiap subgraf dieksekusi oleh \en{device} yang berbeda-beda. Dengan membagi menjadi beberapa subgraf, sebuah \en{device} baru perlu berkomunikasi dengan \en{device} lainnya apabila masuk \en{vertice} yang memiliki \en{dependency} ke \en{vertice} di \en{device} lain.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/tensorflow-graph.png}
    \caption{\en{Dataflow graph} dari program TensorFlow \citep{geron2017hands}.}
    \label{fig:TensorFlowGraph}
\end{figure}

\subsection{Arsitektur}

Gambar ~\ref{fig:TensorFlowArch} menunjukkan arsitektur umum TensorFlow. Berikutnya akan dijelaskan beberapa bagian dari arsitektur tersebut.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.50\linewidth]{figures/tensorflow-arch.png}
    \caption{Arsitektur umum TensorFlow \citep{tensorflow2018architecture}.}
    \label{fig:TensorFlowArch}
\end{figure}

\textbf{Client}. Menerima pendefinisian program TensorFlow dari \en{user}, seperti tensor-tensor yang ada dan operasi-operasi yang dijalankan. Kemudian, \en{client} mengkonstruksi \en{dataflow graph} yang sesuai, lalu mengeksekusi graf tersebut menggunakan \en{session}. \en{Client} tersedia dalam beberapa bahasa, seperti C++ dan Python.

\textbf{Distributed Master.} Merupakan koordinator dari keseluruhan program TensorFlow. Setelah menerima \en{dataflow graph} dari \en{client}, \en{distributed master} mempartisi graf menjadi beberapa subgraf, kemudian mendistribusikannya ke \en{worker services}.

\textbf{Worker Services.} Menerima \en{request} dari \en{master}, menjalankannya pada \en{devices} di bawahnya, kemudian mengirim hasilnya kembali ke \en{master}. \en{Worker service} berelasi satu-satu dengan \en{task}. \en{Task} pada TensorFlow merujuk pada suatu proses TensorFlow, di mana suatu \en{machine} dapat memiliki satu atau lebih \en{task}. Bahkan, suatu \en{device} dapat dibagi-bagi ke beberapa \en{task}.

\textbf{Kernel Implementations.} Merupakan implementasi operasi-operasi TensorFlow yang \en{device-specific}. Tanpa \en{kernel implementation}, \en{backend} TensorFlow tidak dapat berjalan pada suatu \en{device}.

Gambar ~\ref{fig:TensorFlowDist} mengilustrasikan hubungan antar bagian TensorFlow tersebut dalam \en{training} terdistribusi.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/tensorflow-dist.png}
    \caption{Hubungan bagian-bagian terdistribusi di TensorFlow \citep{tensorflow2018architecture}.}
    \label{fig:TensorFlowDist}
\end{figure}

\subsection{Penambahan Operasi}

TensorFlow mendukung penambahan jenis operasi baru, apabila jenis-jenis operasi yang disediakan belum memenuhi kebutuhan pengguna, atau mengoptimisasi operasi yang ada secara \en{native}. Untuk membuat operasi baru, pengguna perlu menambahkan definisi (seperti \en{input} dan \en{output}, bentuk \en{tensor}) dan implementasi operasi tersebut dalam bahasa C++. Selanjutnya, pengguna dapat menambahkan API ke operasi tersebut pada \en{client}, namun langkah ini bersifat opsional.

\section{Penelitian Terkait}

"Training deeper models by GPU memory optimization on TensorFlow" (Meng, 2017) melakukan penelitian untuk mengoptimisasi penggunaan memori GPU saat \en{training} model \en{deep learning} pada TensorFlow \citep{meng2017training}. Penelitian tersebut terbatas pada sebuah komputer dengan satu GPU. Ide dari \en{paper} tersebut adalah menyimpan \en{feature map} model dari memori ke \en{hard disk} saat \en{training} untuk mengurangi penggunaan memori.

Untuk itu, diimplementasikan operasi baru yang disebut (\textbf{swap out/in}) untuk men-\en{swap} \en{feature map} dari memori ke \en{hard disk}. Dengan operasi baru ini, graf TensorFlow yang sudah ada dimodifikasi sehingga operasi disisipkan ke hubungan \en{vertice} yang mengalirkan tensor berukuran besar. Seperti diilustrasikan oleh Gambar ~\ref{fig:SwapOutIn}.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/swap-out-in.png}
    \caption{Graf yang dimodifikasi dengan menyisipkan operasi \textbf{swap out/in} \citep{meng2017training}.}
    \label{fig:SwapOutIn}
\end{figure}

Agar dapat mengoptimisasi dengan baik, perlu dipertimbangkan \en{feature map} mana yang di-\en{swap out}. Apabila semua \en{feature map} di-\en{swap out}, akan menyebabkan penurunan kinerja model karena \en{data transfer overhead}. Maka, \en{feature map} terbaik untuk di-\en{swap out} adalah yang interval hingga diperlukannya kembali cukup lama.

Eksperimen pada \en{paper} dilakukan dengan beberapa \en{pre-trained CNN model} pada sebuah komputer dengan satu GPU (Tesla M40) dengan kapasitas memori 12GB. Menurut eksperimen tersebut, didapatkan bahwa pada model-model yang diuji, ukuran \en{batch} dapat ditingkatkan hingga 3 kali. Sedangkan penggunaan memori maksimum menurun hingga 2-3 kali lipat. Bahkan, model-model seperti ResNet-1001 dan ResNet-2000 yang sebelumnya tidak dapat di-\en{train} karena \en{out of memory} (OOM), menjadi dapat di-\en{train}. Di sisi lain, \en{training speed} mengalami penurunan kurang dari 10\%, karena adanya \en{data transfer overhead}.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.75\linewidth]{figures/swap-out-in-result.png}
    \caption{Perbandingan penggunaan memori dengan \textbf{swap out/in} \citep{meng2017training}.}
    \label{fig:SwapOutInResult}
\end{figure}
