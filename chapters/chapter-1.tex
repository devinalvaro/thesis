\chapter{Pendahuluan}

\section{Latar Belakang} \label{Background}

Pelatihan model \en{deep learning} membutuhkan memori untuk menyimpan berbagai nilai, seperti bobot, bias, hasil fungsi aktivasi, maupun data yang sedang diproses. Maka dari itu, kekurangan memori dapat mengakibatkan kegagalan pelatihan model, karena eror \en{out of memory} (OOM). Mengenai hal ini dijelaskan secara lebih detail di Bagian~\ref{MemoryUsage}.

Masalah tambahan mengenai persoalan OOM adalah kecilnya memori GPU, relatif terhadap memori CPU. Seperti yang dijelaskan di Bagian~\ref{GPU}, GPU memang banyak digunakan untuk pelatihan model, namun ukuran memorinya cenderung lebih terbatas dari memori CPU, sehingga menambah \en{constraint} terhadap masalah OOM.

Salah satu solusi masalah ini adalah \en{memory swapping}, yaitu metode pengurangan beban memori dengan memindahkan isi memori secara temporer ke \en{memory pool} yang lebih besar. Pada kasus pelatihan model \en{deep learning} dengan GPU, sebagian isi memori GPU dapat dipindahkan ke memori CPU secara sementara, kemudian dipindahkan kembali ke GPU ketika dibutuhkan.

Akan tetapi, \en{memory swapping} meningkatkan durasi pelatihan karena adanya \en{memory transfer overhead}, yaitu waktu yang dibutuhkan untuk memindahkan isi memori antara CPU dan GPU. Maka, \en{memory swapping} yang optimal perlu selektif dalam memilih isi memori mana yang di-\en{swap} agar pelatihan model dapat berjalan tanpa OOM, namun tanpa menambah durasi pelatihan secara terlalu besar \citep{meng2017training}.

TensorFlow, sebuah \en{framework} pembelajaran mesin, memiliki fitur \en{memory swapping}. Namun, terdapat potensi bahwa \en{memory swapping} di TensorFlow masih dapat dioptimisasi, seperti yang dijelaskan di Bagian~\ref{OptimizationPotential}. Secara singkat, optimisasi terletak pada pemilihan data mana yang di-\en{swap}, sehingga pada akhirnya mengurangi penambahan durasi pelatihan akibat \en{memory swapping}.

Melihat potensi optimisasi tersebut, fokus tugas akhir ini adalah meneliti dan mengoptimisasi \en{memory swapping} di TensorFlow sehingga lebih optimal dari yang sudah ada, dilihat dari durasi pelatihan.

\section{Rumusan Masalah}

Sebelumnya telah disebutkan bahwa salah satu metode optimisasi memori adalah \en{memory swapping}, yaitu mengurangi beban memori GPU dengan memindahkan isi memori ke CPU secara temporer, seperti yang tersedia pada TensorFlow. Berdasarkan hasil studi literatur dan analisis mekanisme \en{memory swapping} di TensorFlow, terdapat potensi bahwa mekanisme tersebut masih kurang optimal, seperti yang dijelaskan pada Bagian~\ref{OptimizationPotential}. Secara singkat, solusi yang diajukan untuk mengoptimisasi \en{memory swapping} di TensorFlow adalah dengan memprioritaskan \en{swapping} pada \en{tensor} yang interval hingga digunakannya kembali terlama, sehingga meningkatkan \en{overlapping} antara komputasi dengan \en{memory swapping}.

Rumusan masalah pada tugas akhir ini adalah sebagai berikut.

\begin{enumerate}
    \item Bagaimana mengoptimisasi \en{memory swapping} di TensorFlow agar lebih optimal, dilihat dari durasi pelatihan?
    \item Bagaimana kinerja \en{memory swapping} di TensorFlow yang telah dioptimisasi dibandingkan dengan yang sebelumnya?
\end{enumerate}

\section{Tujuan}

Tujuan tugas akhir ini adalah mengoptimisasi \en{memory swapping} di TensorFlow dengan metode yang dijelaskan pada \nameref{SolutionDesign}. Harapan tercapainya tujuan tersebut adalah mengurangi durasi pelatihan dibandingkan dengan menggunakan \en{memory swapping} bawaan TensorFlow.

\section{Batasan Masalah}

Batasan masalah dari tugas akhir ini adalah model yang digunakan berbasis \en{recurrent neural network} (RNN), yang dipilih berdasarkan alasan-alasan yang dijelaskan di Bagian~\ref{WhyRNN}.

\section{Metodologi}

Tahapan pengerjaan tugas akhir ini dimulai dengan melakukan analisis dan merumuskan permasalahan yang akan dipecahkan. Selanjutnya, melakukan pencarian terhadap solusi yang tepat untuk memecahkan permasalahan tersebut, salah satunya dengan melakukan studi literatur. Setelah memutuskan solusi yang tepat, melakukan perancangan solusi serta implementasi yang akan digunakan untuk melakukan eksperimen. Langkah selanjutnya adalah mengimplementasi solusi dan melakukan eksperimen sesuai rancangan yang dibuat sebelumnya. Setelahnya, menganalisis dan mengevaluasi hasil eksperimen hingga akhirnya menarik kesimpulan terhadap rumusan permasalahan dan solusi yang diajukan.

\section{Sistematika Pembahasan}

Tugas akhir ini dibagi menjadi 5 bab, yaitu Pendahuluan, Studi Literatur, Analisis Permasalahan dan Rancangan Solusi, Implementasi dan Pengujian, dan Kesimpulan dan Saran.

Bab I Pendahuluan mengantarkan pembaca kepada topik tugas akhir dengan Latar Belakang, Rumusan Masalah, Tujuan, Batasan Masalah, dan Sistematika Pembahasan agar pembaca mendapatkan gambaran secara garis besar.

Bab II Studi Literatur berisi rangkuman literatur-literatur mengenai topik-topik yang terkait dengan tugas akhir, seperti \en{deep learning}, TensorFlow, GPU, dan lain-lain.

Bab III Analisis Permasalahan dan Rancangan Solusi merupakan hasil analisis terhadap permasalahan yang dihadapi pada tugas akhir ini dan rancangan dari solusi yang menyelesaikan permasalahan tersebut.

Bab IV Implementasi dan Pengujian menjelaskan implementasi dari solusi yang telah dirancang serta memaparkan hasil pengujian implementasi tersebut.

Bab V Kesimpulan dan Saran menyimpulkan dan memberikan saran pengembangan lebih lanjut tugas akhir ini.
