\chapter{Implementasi dan Pengujian} \label{implementationevaluation}

\section{Lingkungan Implementasi dan Pengujian}

Tabel~\ref{table:Specification} berikut memaparkan spesifikasi lingkungan yang digunakan penulis dalam melakukan implementasi dan pengujian.

\begin{longtable}{|l|l|}

\hline
\multicolumn{1}{|c|}{\textbf{Parameter}} & \multicolumn{1}{c|}{\textbf{Spesifikasi}}                                                                                                     \\ \hline
\endfirsthead
\endhead

\textit{Operating System}                & Ubuntu 19.04 64-bit                                                                                                                           \\ \hline
\textit{Processor}                       & Intel Core i7-8550U CPU @ 1.80GHz                                                                                                             \\ \hline
\textit{Memory}                          & 16GB 1866MHz LPDDR3 onboard                                                                                                                   \\ \hline
\textit{GPU}                             & \begin{tabular}[c]{@{}l@{}}NVIDIA GeForce MX150\\ \en{Clockrate}: 1468 MHz\\ \en{Memory}: 2GB\\ \en{Driver}: 418.56\\ CUDA: 10.0\end{tabular} \\ \hline

\caption{Spesifikasi Lingkungan Implementasi dan Uji}
\label{table:Specification}\\

\end{longtable}

\section{Implementasi}

Pada bagian ini dijelaskan mengenai implementasi optimisasi \en{memory swapping} di TensorFlow menurut \nameref{solutiondesign}. Implementasi yang dilakukan berupa modifikasi terhadap \en{source code} TensorFlow, terutama di \en{file} \code{tensorflow/core/\\kernels/stack.cc}.

Secara garis besar, implementasi dapat dibagi menjadi 2 bagian, yaitu modifikasi \code{swapping out} menurut Kode~\ref{lst:SwapOutPseudocodeOptimized} dan \en{swapping in} menurut Kode~\ref{lst:SwapInPseudocodeOptimized}.

\subsection{Modifikasi \en{Swapping Out}}

Pada Kode~\ref{lst:SwapOutPseudocodeOptimized} yang menjelaskan optimisasi \en{swapping out}, terdapat metode \code{get\_\\oldest\_unswapped\_tensor\_id} yang berfungsi mengembalikan indeks dari \en{oldest tensor} yang belum di-\en{swap}. Dari sini, \code{Stack} perlu dimodifikasi untuk mengakomodasi metode tersebut.

Pertama, dibutuhkan sebuah \en{queue} untuk menyimpan indeks-indeks \en{tensor} yang belum di-\en{swap}. \en{Queue} dipilih agar indeks \en{tensor} yang di-\en{dequeue} adalah yang terawal (\en{oldest}). Selanjutnya, metode \code{Push} pada \code{Stack} juga perlu dimodifikasi agar ketika sebuah \en{tensor} di-\en{push} ke \en{stack}, indeksnya juga di-\en{enqueue} ke \en{queue} tersebut. Kode~\ref{lst:UnswappedTensorIds} menunjukkan deklarasi \en{queue} dan modifikasi \code{Push} tersebut.

\begin{lstlisting}[language=C++, caption=Deklarasi \code{unswapped\_ids\_} dan modifikasi \code{Push}, label={lst:UnswappedTensorIds}]
class Stack {
  private:
    // ...
    std::queue<int> unswapped_ids_;

  public:
    // ...
    Status Push(const TensorAndAllocation& value) {
      // ...
      stack_.push_back(value);
      int index = stack_.size() - 1;
      unswapped_ids_.push_back(index);
      return Status::OK();
  }
}
\end{lstlisting}

Setelahnya, dapat diimplementasi metode yang mengambil indeks \en{oldest tensor} yaitu \code{GetTensorToSwapOut}. Metode tersebut mengambil indeks \en{oldest tensor} dari \code{unswapped\_ids\_} kemudian meng-\en{assign} \en{tensor} tersebut ke parameter \en{output} \code{value}. Selain itu, indeks juga di-\en{push} ke \code{swapped\_ids\_} yang akan dijelaskan kemudian. Kode~\ref{lst:GetTensorToSwapOut} merupakan simplifikasi dari implementasi \code{GetTensorToSwapOut}.

\begin{lstlisting}[language=C++, caption=Definisi \code{GetTensorToSwapOut}, label={lst:GetTensorToSwapOut}]
class Stack {
  public:
    // ...
    void GetTensorToSwapOut(TensorAndAllocation** value) {
      if (unswapped_ids_.empty())
        return;

      int index = unswapped_ids_.front();
      unswapped_ids_.pop();
      swapped_ids_.push_back(index);
      *value = &stack_[index];
    }
}
\end{lstlisting}

Berikutnya adalah modifikasi terhadap \code{StackPushOp} mengikuti Kode~\ref{lst:SwapOutPseudocodeOptimized}. Seperti pada \en{pseudocode} tersebut, modifikasi tetap mengikuti heuristik yang ada, yaitu melakukan \en{swapping} ketika memori GPU 70\% penuh, namun yang di-\en{swap out} bukanlah \en{tensor} sekarang, malainkan \en{oldest tensor} yang didapat dari \code{GetTensorToSwapOut}. Implementasi modifikasi ini ditunjukkan oleh Kode~\ref{lst:StackPushOp} dengan beberapa penyederhanaan.

\begin{lstlisting}[language=C++, caption=Modifikasi \code{StackPushOp}, label={lst:StackPushOp}]
void StackPushOp::ComputeAsync(OpKernelContext* ctx, DoneCallback done) {
  // ...

  // Push current tensor to Stack.
  ctx, stack->Push({tensor, alloc_attrs, false});
  ctx->set_output(0, tensor);

  // ...

  // If device memory <= 70% full no need to swap.
  // ...
  static constexpr double kOccupancy = 0.7;
  if (stats.bytes_in_use <= (stats.bytes_limit * kOccupancy)) {
    done();
    return;
  }

  // Obtain the oldest unswapped TensorAndAllocation pointer from queue.
  Stack::TensorAndAllocation* oldest_tensor;
  stack->GetTensorToSwapOut(&oldest_tensor);

  // Asynchronously swap out the oldest tensor.
  // ...
  Tensor* cpu_tensor = ...
  device_ctxt->CopyDeviceTensorToCPU(
      &(oldest_tensor->tensor), "StackPush", device, cpu_tensor,
      [stack, oldest_tensor, cpu_tensor, done](const Status& s) {
        if (s.ok()) {
          oldest_tensor->tensor = *cpu_tensor;
          oldest_tensor->swapped_to_cpu = true;
        }
        done();
        delete cpu_tensor;
      });
}
\end{lstlisting}

Pada bagian terakhir Kode~\ref{lst:StackPushOp} di atas terlihat proses \en{swapping out} yang dilakukan terhadap \en{oldest tensor}. \en{Swapping out} dilakukan secara \en{asynchronous} yang setelah selesai dijalankan memanggil sebuah \en{callback function}. \en{Callback} ini mengubah elemen \en{oldest tensor} di \en{stack}, dari \code{tensor} yang merujuk ke \code{device\_tensor} menjadi \code{cpu\_tensor} dan \code{swapped\_to\_cpu} menjadi \code{true} agar pada \en{swapping in} dapat diketahui bahwa \en{tensor} bersangkutan telah di-\en{swap}. (Lebih detail mengenai \code{tensor} dijelaskan pada Bagian~\ref{tensor}.)

Demikian implementasi pada bagian \en{swapping out}, di mana \en{oldest tensor} di-\en{swap out} agar pada \en{backpropagation} dapat di-\en{swap in} bersamaan dengan berjalannya komputasi, sehingga meningkatkan \en{asynchronicity}. Berikutnya adalah penjelasan mengenai implementasi pada bagian \en{swapping in}.

\subsection{Modifikasi \en{Swapping In}}

Pada bagian ini dijelaskan implementasi menurut Kode~\ref{lst:SwapInPseudocodeOptimized} yang menjelaskan optimisasi pada bagian \en{swapping in}. Namun, sebelum masuk ke bagian tersebut perlu ditunjukkan kode-kode yang mendukung implementasi tersebut.

Sebelumnya, pada Kode~\ref{lst:GetTensorToSwapOut}, indeks di-\en{push} ke \code{swapped\_ids\_}, yaitu sebuah \en{stack} yang menyimpan indeks-indeks \en{tensor} yang di-\en{swap}. Digunakan \en{stack} karena kebalikan dari \en{swapping out}, \en{swapping in} dilakukan terhadap \en{swapped tensor} yang terbaru (\en{most recent}) dahulu. Kode~\ref{lst:SwappedTensorIds} menunjukkan deklarasi \en{swapped\_ids\_}.

\begin{lstlisting}[language=C++, caption=Deklarasi \code{swapped\_ids\_}, label={lst:SwappedTensorIds}]
class Stack {
  private:
    // ...
    std::queue<int> swapped_ids_;
}
\end{lstlisting}

Selanjutnya adalah penjelasan mengenai \code{GetTensorToSwapIn}, metode yang mengambil indeks \en{tensor} selanjutnya harus di-\en{code}. Secara garis besar, metode ini mirip dengan \code{GetTensorToSwapOut} namun terhadap \code{swapped\_ids\_}, seperti ditunjukkan oleh Kode~\ref{lst:GetTensorToSwapIn}

\begin{lstlisting}[language=C++, caption=Definisi \code{GetTensorToSwapIn}, label={lst:GetTensorToSwapIn}]
class Stack {
  public:
    // ...
    void GetTensorToSwapIn(TensorAndAllocation** value) {
      if (swapped_ids_.empty())
        return;

      int index = swapped_ids_.top();
      swapped_ids_.pop();
      *value = &stack_[index];
    }
}
\end{lstlisting}

Berikutnya adalah modifikasi terhadap \code{StackPopOp} mengikuti Kode~\ref{lst:SwapInPseudocodeOptimized}. Seperti pada \en{pseudocode} tersebut, \code{StackPopOp} dimodifikasi sehingga setelah mem-\en{pop} \en{tensor} teratas dari \en{stack}, dilakukan juga \en{swapping in} terhadap \en{tensor}-\en{tensor} berikutnya secara \en{asynchronous} untuk meningkatkan \en{overlapping} antara komputasi dengan \en{memory transfer}. Implementasi modifikasi ini ditunjukkan oleh Kode~\ref{lst:StackPopOp} dengan beberapa penyederhanaan.

\begin{lstlisting}[language=C++, caption=Modifikasi \code{StackPopOp}, label={lst:StackPopOp}]
void StackPopOp::ComputeAsync(OpKernelContext* ctx, DoneCallback done) {
  // ...

  // Pop a tensor from Stack.
  Stack::TensorAndAllocation value;
  OP_REQUIRES_OK_ASYNC(ctx, stack->Pop(&value), done);

  // If the tensor was swapped out, then swap in (not shown for clarity).
  // ...

  // Asynchronously swap "future" tensors.

  // If device memory still > 90% full don't swap in yet.
  // ...
  static constexpr double kOccupancy = 0.7;
  if (stats.bytes_in_use > (stats.bytes_limit * kOccupancy)) {
    return;
  }

  Stack::TensorAndAllocation* swapped_tensor;
  stack->GetTensorToSwapIn(&swapped_tensor);

  Tensor* device_tensor = ...
  device_ctxt->CopyCPUTensorToDevice(
      &(swapped_tensor->tensor), device, device_tensor,
      [stack, swapped_tensor, device_tensor, index](const Status& s) {
        if (s.ok()) {
          swapped_tensor->tensor = *device_tensor;
          swapped_tensor->swapped_to_cpu = false;
        }
        delete device_tensor;
        stack->FinishSwappingIn(index);
      });
}
\end{lstlisting}

Pada bagian Kode~\ref{lst:StackPopOp} di atas terlihat proses \en{swapping in} terhadap "\en{future tensors}", yaitu \en{swapped tensors} yang belum akan digunakan untuk komputasi, dengan tujuan meningkatkan \en{overlapping} antara komputasi dengan \en{memory transfer}, seperti yang telah disebutkan sebelumnya.

Terdapat satu lagi hal yang perlu dibahas, yaitu herustik pada \en{swapping in}. Seperti heuristik pada \en{swapping out}, \en{swapping in} tersebut dilakukan ketika memori GPU hampir penuh. Dipilih nilai yang \code{kOccupancy} yang sama yaitu 0.7, untuk menyamai nilai yang digunakan di \en{swapping out}, karena nilai heuristik tersebut sudah ada di versi bawaan TensorFlow.

Demikian penjelasan mengenai implementasi optimisasi \en{memory swapping} di TensorFlow. Berikutnya dilakukan pengujian terhadap optimisasi ini dibandingkan dengan versi bawaan TensorFlow.

\section{Pengujian}

TBD.
