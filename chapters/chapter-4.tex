\chapter{Implementasi dan Pengujian} \label{implementationevaluation}

\section{Implementasi}

Pada bagian ini dijelaskan mengenai implementasi optimisasi \en{memory swapping} di TensorFlow menurut \nameref{solutiondesign}. Implementasi yang dilakukan berupa modifikasi terhadap \en{source code} TensorFlow, terutama di \en{file} \code{tensorflow/core/\\kernels/stack.cc}.

Secara garis besar, implementasi dapat dibagi menjadi 2 bagian, yaitu modifikasi \code{swapping out} menurut Kode~\ref{lst:SwapOutPseudocodeOptimized} dan \en{swapping in} menurut Kode~\ref{lst:SwapInPseudocodeOptimized}.

\subsection{Modifikasi \en{Swapping Out}}

Pada Kode~\ref{lst:SwapOutPseudocodeOptimized} yang menjelaskan optimisasi \en{swapping out}, terdapat metode \code{get\_\\oldest\_unswapped\_tensor\_id} yang berfungsi mengembalikan indeks dari \en{oldest tensor} yang belum di-\en{swap}. Dari sini, \code{Stack} perlu dimodifikasi untuk mengakomodasi metode tersebut.

Pertama, dibutuhkan sebuah \en{queue} untuk menyimpan indeks-indeks \en{tensor} yang belum di-\en{swap}. \en{Queue} dipilih agar indeks \en{tensor} yang di-\en{dequeue} adalah yang terawal (\en{oldest}). Selanjutnya, metode \code{Push} pada \code{Stack} juga perlu dimodifikasi agar ketika sebuah \en{tensor} di-\en{push} ke \en{stack}, indeksnya juga di-\en{enqueue} ke \en{queue} tersebut. Kode~\ref{lst:UnswappedTensorIds} menunjukkan deklarasi \en{queue} dan modifikasi \code{Push} tersebut.

\begin{lstlisting}[language=C++, caption=Deklarasi \code{unswapped\_ids\_} dan modifikasi \code{Push}, label={lst:UnswappedTensorIds}]
class Stack {
  private:
    // ...
    std::queue<int> unswapped_ids_;

  public:
    // ...
    Status Push(const TensorAndAllocation& value) {
      // ...
      stack_.push_back(value);
      int index = stack_.size() - 1;
      unswapped_ids_.push_back(index);
      return Status::OK();
  }
}
\end{lstlisting}

Setelahnya, dapat diimplementasi metode yang mengambil indeks \en{oldest tensor} yaitu \code{GetTensorToSwapOut}. Metode tersebut mengambil indeks \en{oldest tensor} dari \code{unswapped\_ids\_} kemudian meng-\en{assign} \en{tensor} tersebut ke parameter \en{output} \code{value}. Selain itu, indeks juga di-\en{push} ke \code{swapped\_ids\_} yang akan dijelaskan kemudian. Kode~\ref{lst:GetTensorToSwapOut} merupakan simplifikasi dari implementasi \code{GetTensorToSwapOut}.

\begin{lstlisting}[language=C++, caption=Definisi \code{GetTensorToSwapOut}, label={lst:GetTensorToSwapOut}]
class Stack {
  public:
    // ...
    void GetTensorToSwapOut(TensorAndAllocation** value) {
      if (unswapped_ids_.empty())
        return;

      int index = unswapped_ids_.front();
      unswapped_ids_.pop();
      swapped_ids_.push_back(index);
      *value = &stack_[index];
    }
}
\end{lstlisting}

Berikutnya adalah modifikasi terhadap \code{StackPushOp} mengikuti Kode~\ref{lst:SwapOutPseudocodeOptimized}. Seperti pada \en{pseudocode} tersebut, modifikasi tetap mengikuti heuristik yang ada, yaitu melakukan \en{swapping} ketika memori GPU 70\% penuh, namun yang di-\en{swap out} bukanlah \en{tensor} sekarang, malainkan \en{oldest tensor} yang didapat dari \code{GetTensorToSwapOut}. Implementasi modifikasi ini ditunjukkan oleh Kode~\ref{lst:StackPushOp} dengan beberapa penyederhanaan.

\begin{lstlisting}[language=C++, caption=Modifikasi \code{StackPushOp}, label={lst:StackPushOp}]
void StackPushOp::ComputeAsync(OpKernelContext* ctx, DoneCallback done) {
  // ...

  // Push current tensor to Stack.
  ctx, stack->Push({tensor, alloc_attrs, false});
  ctx->set_output(0, tensor);

  // ...

  // If device memory <= 70% full no need to swap.
  // ...
  static constexpr double kOccupancy = 0.7;
  if (stats.bytes_in_use <= (stats.bytes_limit * kOccupancy)) {
    done();
    return;
  }

  // Obtain the oldest unswapped TensorAndAllocation pointer from queue.
  Stack::TensorAndAllocation* oldest_tensor;
  stack->GetTensorToSwapOut(&oldest_tensor);

  // Asynchronously swap out the oldest tensor.
  // ...
  Tensor* cpu_tensor = ...
  device_ctxt->CopyDeviceTensorToCPU(
      &(oldest_tensor->tensor), "StackPush", device, cpu_tensor,
      [stack, oldest_tensor, cpu_tensor, done](const Status& s) {
        if (s.ok()) {
          oldest_tensor->tensor = *cpu_tensor;
          oldest_tensor->swapped_to_cpu = true;
        }
        done();
        delete cpu_tensor;
      });
}
\end{lstlisting}

Pada bagian terakhir Kode~\ref{lst:StackPushOp} di atas terlihat proses \en{swapping out} yang dilakukan terhadap \en{oldest tensor}. \en{Swapping out} dilakukan secara \en{asynchronous} yang setelah selesai dijalankan memanggil sebuah \en{callback function}. \en{Callback} ini mengubah elemen \en{oldest tensor} di \en{stack}, dari \code{tensor} yang merujuk ke \code{device\_tensor} menjadi \code{cpu\_tensor} dan \code{swapped\_to\_cpu} menjadi \code{true} agar pada \en{swapping in} dapat diketahui bahwa \en{tensor} bersangkutan telah di-\en{swap}. (Lebih detail mengenai \code{tensor} dijelaskan pada Bagian~\ref{tensor}.)

Demikian implementasi pada bagian \en{swapping out}, di mana \en{oldest tensor} di-\en{swap out} agar pada \en{backpropagation} dapat di-\en{swap in} bersamaan dengan berjalannya komputasi, sehingga meningkatkan \en{asynchronicity}. Berikutnya adalah penjelasan mengenai implementasi pada bagian \en{swapping in}.

\subsection{Modifikasi \en{Swapping In}}

Pada bagian ini dijelaskan implementasi menurut Kode~\ref{lst:SwapInPseudocodeOptimized} yang menjelaskan optimisasi pada bagian \en{swapping in}. Namun, sebelum masuk ke bagian tersebut perlu ditunjukkan kode-kode yang mendukung implementasi tersebut.

Sebelumnya, pada Kode~\ref{lst:GetTensorToSwapOut}, indeks di-\en{push} ke \code{swapped\_ids\_}, yaitu sebuah \en{stack} yang menyimpan indeks-indeks \en{tensor} yang di-\en{swap}. Digunakan \en{stack} karena kebalikan dari \en{swapping out}, \en{swapping in} dilakukan terhadap \en{swapped tensor} yang terbaru (\en{most recent}) dahulu. Kode~\ref{lst:SwappedTensorIds} menunjukkan deklarasi \en{swapped\_ids\_}.

\begin{lstlisting}[language=C++, caption=Deklarasi \code{swapped\_ids\_}, label={lst:SwappedTensorIds}]
class Stack {
  private:
    // ...
    std::queue<int> swapped_ids_;
}
\end{lstlisting}

Selanjutnya adalah penjelasan mengenai \code{GetTensorToSwapIn}, metode yang mengambil indeks \en{tensor} selanjutnya harus di-\en{code}. Secara garis besar, metode ini mirip dengan \code{GetTensorToSwapOut} namun terhadap \code{swapped\_ids\_}, seperti ditunjukkan oleh Kode~\ref{lst:GetTensorToSwapIn}

\begin{lstlisting}[language=C++, caption=Definisi \code{GetTensorToSwapIn}, label={lst:GetTensorToSwapIn}]
class Stack {
  public:
    // ...
    void GetTensorToSwapIn(TensorAndAllocation** value) {
      if (swapped_ids_.empty())
        return;

      int index = swapped_ids_.top();
      swapped_ids_.pop();
      *value = &stack_[index];
    }
}
\end{lstlisting}

Berikutnya adalah modifikasi terhadap \code{StackPopOp} mengikuti Kode~\ref{lst:SwapInPseudocodeOptimized}. Seperti pada \en{pseudocode} tersebut, \code{StackPopOp} dimodifikasi sehingga setelah mem-\en{pop} \en{tensor} teratas dari \en{stack}, dilakukan juga \en{swapping in} terhadap \en{tensor}-\en{tensor} berikutnya secara \en{asynchronous} untuk meningkatkan \en{overlapping} antara komputasi dengan \en{memory transfer}. Implementasi modifikasi ini ditunjukkan oleh Kode~\ref{lst:StackPopOp} dengan beberapa penyederhanaan.

\begin{lstlisting}[language=C++, caption=Modifikasi \code{StackPopOp}, label={lst:StackPopOp}]
void StackPopOp::ComputeAsync(OpKernelContext* ctx, DoneCallback done) {
  // ...

  // Pop a tensor from Stack.
  Stack::TensorAndAllocation value;
  OP_REQUIRES_OK_ASYNC(ctx, stack->Pop(&value), done);

  // If the tensor was swapped out, then swap in (not shown for clarity).
  // ...

  // Asynchronously swap "future" tensors.

  // If device memory still > 90% full don't swap in yet.
  // ...
  static constexpr double kOccupancy = 0.7;
  if (stats.bytes_in_use > (stats.bytes_limit * kOccupancy)) {
    return;
  }

  Stack::TensorAndAllocation* swapped_tensor;
  stack->GetTensorToSwapIn(&swapped_tensor);

  Tensor* device_tensor = ...
  device_ctxt->CopyCPUTensorToDevice(
      &(swapped_tensor->tensor), device, device_tensor,
      [stack, swapped_tensor, device_tensor, index](const Status& s) {
        if (s.ok()) {
          swapped_tensor->tensor = *device_tensor;
          swapped_tensor->swapped_to_cpu = false;
        }
        delete device_tensor;
        stack->FinishSwappingIn(index);
      });
}
\end{lstlisting}

Pada bagian Kode~\ref{lst:StackPopOp} di atas terlihat proses \en{swapping in} terhadap "\en{future tensors}", yaitu \en{swapped tensors} yang belum akan digunakan untuk komputasi, dengan tujuan meningkatkan \en{overlapping} antara komputasi dengan \en{memory transfer}, seperti yang telah disebutkan sebelumnya.

Terdapat satu lagi hal yang perlu dibahas, yaitu herustik pada \en{swapping in}. Seperti heuristik pada \en{swapping out}, \en{swapping in} tersebut dilakukan ketika memori GPU hampir penuh. Dipilih nilai yang \code{kOccupancy} yang sama yaitu 0.7, untuk menyamai nilai yang digunakan di \en{swapping out}, karena nilai heuristik tersebut sudah ada di versi bawaan TensorFlow.

Demikian penjelasan mengenai implementasi optimisasi \en{memory swapping} di TensorFlow. Berikutnya dilakukan pengujian terhadap optimisasi ini dibandingkan dengan versi bawaan TensorFlow.

\section{Pengujian}

Pada bagian ini dijelaskan mengenai pengujian terhadap optimisasi \en{memory swapping} di TensorFlow yang telah diimplementasikan. Berikut dijelaskan lingkungan pengujian, metode pengujian, dan hasil pengujian dalam berbagai kasus pengujian.

\section{Lingkungan Pengujian}

Tabel~\ref{table:Specification} memaparkan spesifikasi lingkungan yang digunakan penulis dalam melakukan pengujian.

{\renewcommand{\arraystretch}{0.75}
\begin{table}[]
\centering
\caption{Spesifikasi Lingkungan Pengujian}
\label{table:Specification}
\begin{tabular}{|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{Original}} & \multicolumn{1}{c|}{\textbf{Optimized}} \\ \hline
\en{Operating System}                   & Ubuntu 18.04 64-bit                                                                                            \\ \hline
\en{Processor}                          & Intel Xeon CPU @ 2.20GHz                                                                                       \\ \hline
\en{Memory}                             & 12 GB                                                                                                          \\ \hline
\en{GPU}                                & \begin{tabular}[c]{@{}l@{}}NVIDIA Tesla P4\\ \en{Memory}: 8 GB\\ \en{Driver}: 418.56\\ CUDA: 10.0\end{tabular} \\ \hline
\end{tabular}
\end{table}}

\subsection{Metode Pengujian}

Pengujian dilakukan dengan melakukan beberapa kali \en{training} menggunakan TensorFlow asli dan teroptimisasi, kemudian durasi \en{trainig} kedua perlakuan dibandingkan dan dihitung rataannya. Selain itu, dilakukan uji statistik lain seperti \en{t-test} untuk memastikan bahwa durasi \en{training} kedua perlakuan memang berbeda.

\en{To be continued}.

\subsection{Hasil Pengujian}

Berikut ditunjukkan hasil pengujian antara TensorFlow asli dan teroptimisasi dalam berbagai kasus pengujian.

\subsubsection{Kasus Pertama}

Pada pengujian pertama, digunakan parameter-parameter sebagai berikut.

\begin{enumerate}
  \item Ukuran \en{batch}: 3000
  \item Jumlah \en{hidden layer}: 8
  \item Ukuran \en{hidden layer}: 512
  \item Jumlah \en{unrolling}: 50
  \item Jumlah \en{epoch}: 1000
\end{enumerate}

Tabel~\ref{table:First} menunjukkan durasi \en{training} (dalam satuan detik) kedua perlakuan pada masing-masing 10 kali percobaan. Dari hasil pengujian tersebut, terlihat bahwa versi teroptimisasi berhasil mengurangi durasi \en{training} sekitar 3.1\%. Menurut uji statistik \en{t-test}, didapatkan \en{p-value} bernilai 8.7645e-15, sehingga secara statistik dapat dinyatakan bahwa kedua perlakuan berbeda secara signifikan.

\begin{table}[]
\centering
\caption{Hasil pengujian kasus pertama}
\label{table:First}
\small
\begin{tabular}{lll}
\hline
\multicolumn{1}{|l|}{i}  & \multicolumn{1}{c|}{\textbf{Original}}  & \multicolumn{1}{c|}{\textbf{Optimized}} \\ \hline
\multicolumn{1}{|l|}{1}  & \multicolumn{1}{l|}{1710.8475177288055} & \multicolumn{1}{l|}{1659.8958191871643} \\ \hline
\multicolumn{1}{|l|}{2}  & \multicolumn{1}{l|}{1708.529179573059}  & \multicolumn{1}{l|}{1657.4155213832855} \\ \hline
\multicolumn{1}{|l|}{3}  & \multicolumn{1}{l|}{1718.1575810909271} & \multicolumn{1}{l|}{1657.545005083084}  \\ \hline
\multicolumn{1}{|l|}{4}  & \multicolumn{1}{l|}{1711.9896774291992} & \multicolumn{1}{l|}{1664.026943206787}  \\ \hline
\multicolumn{1}{|l|}{5}  & \multicolumn{1}{l|}{1716.2954456806183} & \multicolumn{1}{l|}{1660.8334894180298} \\ \hline
\multicolumn{1}{|l|}{6}  & \multicolumn{1}{l|}{1710.3181750774384} & \multicolumn{1}{l|}{1650.7439186573029} \\ \hline
\multicolumn{1}{|l|}{7}  & \multicolumn{1}{l|}{1710.8965182304382} & \multicolumn{1}{l|}{1659.6190533638}    \\ \hline
\multicolumn{1}{|l|}{8}  & \multicolumn{1}{l|}{1722.2678709030151} & \multicolumn{1}{l|}{1670.1134555339813} \\ \hline
\multicolumn{1}{|l|}{9}  & \multicolumn{1}{l|}{1714.1357491016388} & \multicolumn{1}{l|}{1656.9861009120941} \\ \hline
\multicolumn{1}{|l|}{10} & \multicolumn{1}{l|}{}                   & \multicolumn{1}{l|}{1659.0270841121674} \\ \hline
\textbf{Mean}            & 1713.7153                               & 1659.62064
\end{tabular}
\end{table}

\subsubsection{Kasus Kedua}

Pada pengujian kedua, digunakan parameter-parameter yang sama dengan pengujian sebelumnya, tetapi dengan jumlah \en{epoch} digandakan.

\begin{enumerate}
  \item Ukuran \en{batch}: 3000
  \item Jumlah \en{hidden layer}: 8
  \item Ukuran \en{hidden layer}: 512
  \item Jumlah \en{unrolling}: 50
  \item Jumlah \en{epoch}: 2000
\end{enumerate}

Tabel~\ref{table:Second} menunjukkan durasi \en{training} (dalam satuan detik) kedua perlakuan pada masing-masing 10 kali percobaan. Dari hasil pengujian tersebut, terlihat bahwa versi teroptimisasi berhasil mengurangi durasi \en{training} sekitar 3.4\%. Menurut uji statistik \en{t-test}, didapatkan \en{p-value} bernilai 3.3438e-16, sehingga secara statistik dapat dinyatakan bahwa kedua perlakuan berbeda secara signifikan.

\begin{table}[]
\centering
\caption{Hasil pengujian kasus kedua}
\label{table:Second}
\small
\begin{tabular}{cll}
\hline
\multicolumn{1}{|c|}{i}           & \multicolumn{1}{c|}{\textbf{Original}}  & \multicolumn{1}{c|}{\textbf{Optimized}} \\ \hline
\multicolumn{1}{|c|}{1}           & \multicolumn{1}{l|}{3419.5844151973724} & \multicolumn{1}{l|}{3310.971428632736}  \\ \hline
\multicolumn{1}{|c|}{2}           & \multicolumn{1}{l|}{3432.882806301117}  & \multicolumn{1}{l|}{3315.9460911750793} \\ \hline
\multicolumn{1}{|c|}{3}           & \multicolumn{1}{l|}{3413.0236432552338} & \multicolumn{1}{l|}{3304.504233598709}  \\ \hline
\multicolumn{1}{|c|}{4}           & \multicolumn{1}{l|}{3421.1436865329742} & \multicolumn{1}{l|}{3314.9957132339478} \\ \hline
\multicolumn{1}{|c|}{5}           & \multicolumn{1}{l|}{3402.4240250587463} & \multicolumn{1}{l|}{3328.4635627269745} \\ \hline
\multicolumn{1}{|c|}{6}           & \multicolumn{1}{l|}{3415.1220932006836} & \multicolumn{1}{l|}{3312.9601073265076} \\ \hline
\multicolumn{1}{|c|}{7}           & \multicolumn{1}{l|}{3414.628209590912}  & \multicolumn{1}{l|}{3313.3753986358643} \\ \hline
\multicolumn{1}{|c|}{8}           & \multicolumn{1}{l|}{3411.1480510234833} & \multicolumn{1}{l|}{3307.7781500816345} \\ \hline
\multicolumn{1}{|c|}{9}           & \multicolumn{1}{l|}{3414.513864994049}  & \multicolumn{1}{l|}{3327.114767551422}  \\ \hline
\multicolumn{1}{|c|}{10}          & \multicolumn{1}{l|}{3422.7600326538086} & \multicolumn{1}{l|}{3325.095719099045}  \\ \hline
\multicolumn{1}{l}{\textbf{Mean}} & 3416.72308                              & 3316.12052
\end{tabular}
\end{table}
