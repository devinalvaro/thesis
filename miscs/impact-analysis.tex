\section{Abstrak Tugas Akhir}

\en{Deep neural network} pada umumnya terdiri dari banyak \en{layer} dan neuron, serta memerlukan data berukuran besar untuk mendapatkan kinerja optimal. Faktor-faktor ini menimbulkan beberapa permasalahan pada saat melatih model, seperti panjangnya durasi pelatihan dan besarnya sumber daya komputasi yang dibutuhkan untuk melatih model.

Salah satu sumber daya yang dibutuhkan pada pelatihan model adalah memori. Melatih model \en{deep learning} membutuhkan semakin banyak memori seiring bertambahnya jumlah \en{layer}, neuron, dan ukuran data. Ditambah lagi, melatih model \en{deep neural network} sering menggunakan GPU untuk mengurangi durasi pelatihan, namun  kapasitas memori GPU cenderung lebih kecil dibandingkan dengan kapasitas memori CPU. Maka dari itu, dibutuhkan optimisasi memori untuk melatih model \en{deep neural network} yang semakin besar, terutama pada GPU.

Salah satu \en{framework} \en{deep learning}, TensorFlow, mendukung optimisasi memori dengan \en{memory swapping}, yaitu memindahkan isi memori dari GPU ke CPU secara temporer. Akan tetapi, heuristik \en{memory swapping} pada TensorFlow relatif sederhana, yaitu melakukan \en{memory swapping} baru ketika memori GPU hampir penuh. Menurut sebuah \en{paper} referensi, heuristik ini kurang optimal karena \en{swapping} ketika memori sudah hampir penuh mengurangi \en{overlapping} antara komputasi dengan \en{asynchronous data transfer} (perpindahan data antara memori GPU dan CPU secara \en{asynchronous}).

Pada tugas akhir ini, penulis bertujuan mengimplementasi optimisasi \en{memory swapping} pada TensorFlow dengan metode yang dijelaskan pada \en{paper} referensi tersebut. Secara singkat, metode \en{memory swapping} yang akan diimplementasikan memanfaatkan topologi dari \en{neural network} itu sendiri, yaitu memprioritaskan \en{layer}-\en{layer} awal karena jeda waktu dari \en{forward pass} hingga digunakan kembali saat \en{backpropagation} paling tinggi. Karena jeda waktu yang tinggi tersebut, diharapkan \en{overlapping} antara komputasi dengan \en{asynchronous data transfer} antara memori GPU dan CPU menjadi lebih tinggi, sehingga berpotensi mengurangi durasi pelatihan.

Harapan tercapainya tujuan ini adalah dengan sumber daya yang sama, jumlah \en{layer} dan neuron model serta ukuran \en{batch} dapat ditingkatkan, dapat dilatih model-model yang sebelumnya tidak dapat dilatih karena kelebihan penggunaan memori, mengurangi durasi pelatihan bila dibandingkan dengan menggunakan \en{memory swapping} yang asli dari TensorFlow (dengan alasan yang telah dijelaskan sebelumnya).

\section{Dampak Tugas Akhir}

Dampak diterapkannya optimisasi memori di TensorFlow pada tugas akhir ini terbagi menjadi positif dan negatif. Dampak positifnya adalah untuk sumber daya yang sama, penggunaan memori maksimum saat pelatihan model menjadi berkurang karena sebagian \en{tensor} dipindah dari memori GPU ke CPU. Karena penggunaan memori berkurang, topologi model pun dapat diperbesar (menambah \en{layer}, neuron, dan lainnya), serta model yang sebelumnya tidak dapat dilatih karena \en{out of memory} mungkin menjadi dapat dilatih. Karena itu, optimisasi ini dapat membantu peneliti atau \en{engineer} yang kesulitan melatih model karena kapasitas memori yang terbatas.

Selain itu, bila dibandingkan dengan \en{memory swapping} yang asli dari TensorFlow, bila optimisasi berhasil, maka durasi pelatihan dapat menjadi lebih singkat karena meningkatkan \en{overlapping} antara komputasi dengan \en{asynchronous data transfer}, seperti yang telah dijelaskan sebelumnya.

Kemudian, dampak negatif diterapkannya optimisasi ini adalah bila dibandingkan dengan pelatihan tanpa \en{memory swapping} di TensorFlow, durasi pelatihan berpotensi menjadi lebih lambat karena adanya \en{communication overhead} yang disebabkan perpindahan data antara memori GPU dan CPU. Selain itu, karena optimisasi berupa modifikasi terhadap \en{source code} TensorFlow, maka optimisasi membuat versi TensorFlow tidak lagi sama dengan versi yang \en{official}.
